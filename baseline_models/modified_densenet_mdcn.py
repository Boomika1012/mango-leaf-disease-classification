# -*- coding: utf-8 -*-
"""Modified DenseNet-MDCN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QiJnuem9eGVWYK1Wn_a7QaMW74wRI0RY
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle

!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!mkdir -p /kaggle/working/mangoleaf

!kaggle datasets download -d tahmidmir/mangoleaf -p /kaggle/working/mangoleaf --unzip

!ls -R /kaggle/working/mangoleaf | head -n 120

import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score
import tensorflow as tf
from tensorflow.keras import layers, Model, optimizers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.applications import DenseNet121

DATASET_PATH = "/kaggle/working/mangoleaf/MangoLeafBD"
TRAIN_DIR = os.path.join(DATASET_PATH, "Train")
TEST_DIR  = os.path.join(DATASET_PATH, "Test")

IMG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 30
MODEL_FILE = "mdcn_best.keras"

# Create data generators for training, validation, and testing
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.15,
    height_shift_range=0.15,
    shear_range=0.15,
    zoom_range=0.15,
    horizontal_flip=True,
    brightness_range=[0.8, 1.2],
    fill_mode="nearest",
    validation_split=0.2
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(
    TRAIN_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

val_gen = train_datagen.flow_from_directory(
    TRAIN_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation',
    shuffle=True
)

test_gen = test_datagen.flow_from_directory(
    TEST_DIR,
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

class_names = list(train_gen.class_indices.keys())
num_classes = len(class_names)

# Build the DenseNet121 model with custom classification layers
base = DenseNet121(weights="imagenet", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))
base.trainable = False

x = layers.GlobalAveragePooling2D()(base.output)
x = layers.Dense(512, activation='relu')(x)
x = layers.BatchNormalization()(x)
x = layers.Dropout(0.4)(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.Dropout(0.3)(x)

outputs = layers.Dense(num_classes, activation='softmax')(x)

mdcn_model = Model(inputs=base.input, outputs=outputs)

# Compile the model and define training callbacks
mdcn_model.compile(
    optimizer=optimizers.Adam(1e-4),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

callbacks = [
    EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1),
    ModelCheckpoint(MODEL_FILE, save_best_only=True, monitor='val_loss', verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=3, min_lr=1e-6, verbose=1)
]

# Train the model with frozen base layers
history = mdcn_model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=EPOCHS,
    callbacks=callbacks
)

# Unfreeze base model layers and fine-tune with lower learning rate
base.trainable = True

mdcn_model.compile(
    optimizer=optimizers.Adam(1e-5),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

fine_tune_history = mdcn_model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10,
    callbacks=callbacks
)

# Evaluate the model using test data and calculate performance metrics
y_true = test_gen.classes
y_prob = mdcn_model.predict(test_gen, verbose=1)
y_pred = np.argmax(y_prob, axis=1)

cm = confusion_matrix(y_true, y_pred)
acc = accuracy_score(y_true, y_pred)
prec = precision_score(y_true, y_pred, average='macro', zero_division=0)
recall = recall_score(y_true, y_pred, average='macro', zero_division=0)
f1s = f1_score(y_true, y_pred, average='macro', zero_division=0)
sensitivity = np.mean(np.diag(cm) / np.sum(cm, axis=1))
specificity = np.mean([cm[i,i]/(np.sum(cm)-np.sum(cm[i,:])) for i in range(num_classes)])
cohen_kappa = cohen_kappa_score(y_true, y_pred)

y_true_onehot = tf.keras.utils.to_categorical(y_true, num_classes=num_classes)
try:
    roc_auc = roc_auc_score(y_true_onehot, y_prob, multi_class='ovr')
except:
    roc_auc = None

print(f"Accuracy: {acc:.4f}")
print(f"Precision: {prec:.4f}")
print(f"Recall: {recall:.4f}")
print(f"Sensitivity: {sensitivity:.4f}")
print(f"Specificity: {specificity:.4f}")
print(f"F1 Score: {f1s:.4f}")
print(f"Cohen Kappa: {cohen_kappa:.4f}")
if roc_auc:
    print(f"ROC-AUC: {roc_auc:.4f}")

# Plot accuracy and loss curves for training and validation
import seaborn as sns
plt.figure()
plt.plot(history.history['accuracy'] + fine_tune_history.history['accuracy'], label='train_acc')
plt.plot(history.history['val_accuracy'] + fine_tune_history.history['val_accuracy'], label='val_acc')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.figure()
plt.plot(history.history['loss'] + fine_tune_history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'] + fine_tune_history.history['val_loss'], label='val_loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

print(os.path.abspath(MODEL_FILE))