# -*- coding: utf-8 -*-
"""NOVEL SEGMENTATION

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DFB_FEjQVenPBtc2ZpTN6xskK2YWcN_V
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle

!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!mkdir -p /kaggle/working/mangoleaf

!kaggle datasets download -d tahmidmir/mangoleaf -p /kaggle/working/mangoleaf --unzip

!ls -R /kaggle/working/mangoleaf | head -n 120

import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from glob import glob
from tqdm import tqdm
from skimage.feature import local_binary_pattern
from skimage.color import rgb2lab, rgb2hsv
from scipy.stats import kurtosis, skew
from scipy.stats import entropy as sp_entropy
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.cross_decomposition import CCA
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import seaborn as sns
DATASET_PATH = "/kaggle/working/mangoleaf/MangoLeafBD"
TRAIN_DIR = os.path.join(DATASET_PATH, "Train")
TEST_DIR = os.path.join(DATASET_PATH, "Test")
IMG_SIZE = 256

def vein_segmentation_readable(path):
    img_bgr = cv2.imread(path)
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    img_resized = cv2.resize(img_rgb, (IMG_SIZE, IMG_SIZE))
    gray = cv2.cvtColor(img_resized, cv2.COLOR_RGB2GRAY)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    gray_clahe = clahe.apply(gray)
    kernel = np.ones((9,9), np.float32)/(9*9)
    avg = cv2.filter2D(gray_clahe, -1, kernel)
    avg_norm = cv2.normalize(avg, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    diff = cv2.subtract(gray_clahe, avg_norm)
    t_old = 128.0
    for _ in range(100):
        foreground = diff[diff >= t_old]
        background = diff[diff < t_old]
        if foreground.size == 0 or background.size == 0:
            break
        mf = foreground.mean()
        mb = background.mean()
        t_new = 0.5*(mf + mb)
        if abs(t_new - t_old) < 0.5:
            break
        t_old = t_new
    _, th = cv2.threshold(diff, int(t_old), 255, cv2.THRESH_BINARY)
    th_inv = cv2.bitwise_not(th)
    mask = th_inv.astype(np.uint8)
    mask3 = cv2.merge([mask,mask,mask])
    segmented = cv2.bitwise_and(img_resized, img_resized, mask=mask)
    return segmented, mask

def build_file_dataframe(dir_path):
    rows = []
    for cls in sorted(os.listdir(dir_path)):
        clsp = os.path.join(dir_path, cls)
        if not os.path.isdir(clsp):
            continue
        for f in glob(os.path.join(clsp, "*")):
            if f.lower().endswith((".jpg",".png",".jpeg")):
                rows.append((f, cls))
    df = pd.DataFrame(rows, columns=["path","label"])
    return df

train_df = build_file_dataframe(TRAIN_DIR)
test_df = build_file_dataframe(TEST_DIR)
le = LabelEncoder()
train_df['label_enc'] = le.fit_transform(train_df['label'])
test_df['label_enc'] = le.transform(test_df['label'])
class_names = list(le.classes_)
print(len(train_df), "train images", len(test_df), "test images")
seg_sample, mask_sample = vein_segmentation_readable(train_df['path'].iloc[0])
plt.figure(figsize=(8,4)); plt.subplot(1,2,1); plt.imshow(seg_sample); plt.axis('off'); plt.title('seg'); plt.subplot(1,2,2); plt.imshow(mask_sample,cmap='gray'); plt.axis('off'); plt.title('mask'); plt.show()

def channel_stats(arr):
    mean = arr.mean()
    stdv = arr.std()
    var = arr.var()
    hist, _ = np.histogram(arr.flatten(), bins=256, range=(0,255), density=True)
    ent = sp_entropy(hist + 1e-12, base=2)
    kr = kurtosis(arr.flatten(), fisher=False, bias=False)
    sk = skew(arr.flatten(), bias=False)
    return np.array([mean, stdv, var, ent, kr, sk], dtype=np.float32)

def color_texture_features_from_segmented(segmented):
    rgb = segmented.copy()
    lab = rgb2lab(rgb).astype(np.float32)
    hsv = rgb2hsv(rgb).astype(np.float32)
    features = []
    for c in range(3):
        features.append(channel_stats(rgb[:,:,c].astype(np.float32)))
    for c in range(3):
        ch = hsv[:,:,c]
        ch255 = (ch*255).astype(np.float32)
        features.append(channel_stats(ch255))
    for c in range(3):
        ch = lab[:,:,c]
        ch_norm = ((ch - ch.min())/(ch.max()-ch.min()+1e-9))*255
        features.append(channel_stats(ch_norm.astype(np.float32)))
    features_flat = np.hstack(features)
    lbp = local_binary_pattern(cv2.cvtColor(segmented, cv2.COLOR_RGB2GRAY), P=8, R=1, method='uniform')
    n_bins = int(lbp.max() + 1)
    lbp_hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)
    lbp_hist_resized = np.pad(lbp_hist, (0, 256 - lbp_hist.size), 'constant')[:256]
    return features_flat, lbp_hist_resized.astype(np.float32)

def extract_features_dataframe(df):
    color_feats = []
    lbp_feats = []
    labels = []
    for p, labl in tqdm(zip(df['path'], df['label_enc']), total=len(df)):
        seg, mask = vein_segmentation_readable(p)
        cfeat, lfeat = color_texture_features_from_segmented(seg)
        color_feats.append(cfeat)
        lbp_feats.append(lfeat)
        labels.append(labl)
    return np.vstack(color_feats), np.vstack(lbp_feats), np.array(labels,dtype=np.int32)

train_color, train_lbp, y_train = extract_features_dataframe(train_df)
test_color, test_lbp, y_test = extract_features_dataframe(test_df)
print("train_color", train_color.shape, "train_lbp", train_lbp.shape)

scaler_color = StandardScaler()
scaler_lbp = StandardScaler()
train_color_s = scaler_color.fit_transform(train_color)
test_color_s = scaler_color.transform(test_color)
train_lbp_s = scaler_lbp.fit_transform(train_lbp)
test_lbp_s = scaler_lbp.transform(test_lbp)
n_comp_color = min(100, train_color_s.shape[1])
n_comp_lbp = min(50, train_lbp_s.shape[1])
cca = CCA(n_components=min(n_comp_color,n_comp_lbp))
cca.fit(train_color_s, train_lbp_s)
train_c1, train_c2 = cca.transform(train_color_s, train_lbp_s)
test_c1, test_c2 = cca.transform(test_color_s, test_lbp_s)
train_fused = np.hstack([train_c1, train_c2])
test_fused = np.hstack([test_c1, test_c2])
scaler_final = StandardScaler()
train_final = scaler_final.fit_transform(train_fused)
test_final = scaler_final.transform(test_fused)
print("train_final", train_final.shape, "test_final", test_final.shape)

svm = SVC(kernel='poly', degree=3, C=1.0, probability=True, random_state=42)
svm.fit(train_final, y_train)
y_pred = svm.predict(test_final)
y_prob = svm.predict_proba(test_final)
cm = confusion_matrix(y_test, y_pred)
acc = accuracy_score(y_test, y_pred)
prec = precision_score(y_test, y_pred, average='macro', zero_division=0)
rec = recall_score(y_test, y_pred, average='macro', zero_division=0)
f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)
try:
    y_test_onehot = np.eye(len(class_names))[y_test]
    roc = roc_auc_score(y_test_onehot, y_prob, multi_class='ovr')
except:
    roc = None
print("Accuracy:", round(acc,4))
print("Precision:", round(prec,4))
print("Recall:", round(rec,4))
print("F1 Score:", round(f1,4))
if roc is not None:
    print("ROC-AUC:", round(roc,4))
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()