# -*- coding: utf-8 -*-
"""Proposed_Algorihtm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1blIrV2lS7vBvrThTKjEh9uFbEuNGa5-z
"""

import numpy as np
import pandas as pd

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import os

print("Available folders in /kaggle/input:")
!ls /kaggle/input

dataset_base = '/kaggle/input/mangoleaf'

path_option_1 = os.path.join(dataset_base, 'MangoLeafBD', 'Train')
path_option_2 = os.path.join(dataset_base, 'Train')

if os.path.exists(path_option_1):
    train_path = path_option_1
    test_path = os.path.join(dataset_base, 'MangoLeafBD', 'Test')
elif os.path.exists(path_option_2):
    train_path = path_option_2
    test_path = os.path.join(dataset_base, 'Test')
else:
    raise FileNotFoundError("Couldn't find Train/Test folders. Check dataset folder names under /kaggle/input.")

print(f"\n Train path: {train_path}")
print(f" Test path: {test_path}")
print("Train exists:", os.path.exists(train_path))
print("Test exists:", os.path.exists(test_path))

import os
import numpy as np
import pandas as pd
import cv2
from glob import glob
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, Model, optimizers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.applications import EfficientNetB0, ResNet50, DenseNet121
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, matthews_corrcoef, classification_report, roc_curve, auc
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import seaborn as sns
from sklearn.cluster import KMeans

SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)

import os

DATASET_PATH = "/kaggle/input/mangoleaf/MangoLeafBD"
TRAIN_DIR = os.path.join(DATASET_PATH, "Train")
TEST_DIR = os.path.join(DATASET_PATH, "Test")

IMG_SIZE = (224, 224)
BATCH_SIZE = 16
EPOCHS_BASE = 15
EPOCHS_FINE = 10

import os
import pandas as pd
from glob import glob
from sklearn.preprocessing import LabelEncoder

def create_image_dataframe(base_dir):
    images, labels = [], []
    for cls in os.listdir(base_dir):
        cls_path = os.path.join(base_dir, cls)
        if os.path.isdir(cls_path):
            for img_file in glob(os.path.join(cls_path, "*.jpg")):
                images.append(img_file)
                labels.append(cls)
    return pd.DataFrame({"image_path": images, "label": labels})

DATASET_PATH = "/kaggle/input/mangoleaf/MangoLeafBD"
TRAIN_DIR = os.path.join(DATASET_PATH, "Train")
TEST_DIR = os.path.join(DATASET_PATH, "Test")

train_df = create_image_dataframe(TRAIN_DIR)
test_df = create_image_dataframe(TEST_DIR)

le = LabelEncoder()
train_df["label_enc"] = le.fit_transform(train_df["label"])
test_df["label_enc"] = le.transform(test_df["label"])

num_classes = len(le.classes_)
print("Classes:", list(le.classes_))
print(f"Train samples: {len(train_df)}, Test samples: {len(test_df)}")

def segment_leaf(image_path, method='clahe_hsv'):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l = clahe.apply(l)
    lab = cv2.merge([l, a, b])
    img_clahe = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)

    if method == 'clahe_hsv':
        hsv = cv2.cvtColor(img_clahe, cv2.COLOR_RGB2HSV)
        lower_green, upper_green = np.array([25, 40, 40]), np.array([90, 255, 255])
        mask_green = cv2.inRange(hsv, lower_green, upper_green)
        lower_brown, upper_brown = np.array([10, 100, 20]), np.array([20, 255, 200])
        mask_brown = cv2.inRange(hsv, lower_brown, upper_brown)
        mask = cv2.bitwise_or(mask_green, mask_brown)
        result = cv2.bitwise_and(img_clahe, img_clahe, mask=mask)

    elif method == 'gaussian_thresh':
        blur = cv2.GaussianBlur(img, (5, 5), 0)
        gray = cv2.cvtColor(blur, cv2.COLOR_RGB2GRAY)
        _, mask = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY)
        result = cv2.bitwise_and(img, img, mask=mask)

    elif method == 'median_edge':
        blur = cv2.medianBlur(img, 5)
        edges = cv2.Canny(blur, 50, 150)
        mask = cv2.dilate(edges, None, iterations=1)
        result = cv2.bitwise_and(img, img, mask=mask)

    elif method == 'gray_mask':
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        _, mask = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)
        result = cv2.bitwise_and(img, img, mask=mask)

    else:
        result = img_clahe

    result = cv2.resize(result, IMG_SIZE)
    return result / 255.0

sample_image = train_df["image_path"].iloc[0]

methods = ['clahe_hsv', 'gaussian_thresh', 'median_edge', 'gray_mask']
titles = [
    "CLAHE + HSV (Green + Brown)  [Best]",
    "Gaussian Blur + Thresholding",
    "Median Filter + Edge Detection",
    "Grayscale + Intensity Mask"
]

plt.figure(figsize=(14, 8))
for i, method in enumerate(methods):
    img = segment_leaf(sample_image, method=method)
    plt.subplot(2, 2, i+1)
    plt.imshow(img)
    plt.title(titles[i], fontsize=12)
    plt.axis("off")
plt.tight_layout()
plt.show()

summary_data = {
    "Method": [
        "CLAHE + HSV (Green + Brown)",
        "Gaussian Blur + Thresholding",
        "Median Filter + Edge Detection",
        "Grayscale + Intensity Mask"
    ],
    "Preprocessing Used": [
        "CLAHE (Contrast Limited Adaptive Histogram Equalization)",
        "Gaussian Blur",
        "Median Blur",
        "None (Grayscale Conversion)"
    ],
    "Segmentation Used": [
        "HSV Color Segmentation (Green + Brown ranges)",
        "Simple Threshold Segmentation",
        "Canny Edge Detection",
        "Intensity-Based Masking"
    ]
}

method_df = pd.DataFrame(summary_data)
print("\n Preprocessing and Segmentation Techniques Used:\n")
display(method_df)

def generator(df, batch_size=BATCH_SIZE):
    while True:
        batch = df.sample(batch_size)
        batch_x = np.array([segment_leaf(p, method='clahe_hsv') for p in batch["image_path"]])
        batch_y = tf.keras.utils.to_categorical(batch["label_enc"], num_classes)
        yield batch_x, batch_y

def build_model(base):
    x = layers.Dense(256, activation="relu")(base.output)
    out = layers.Dense(num_classes, activation="softmax")(x)
    model = Model(base.input, out)
    model.compile(optimizer=optimizers.Adam(1e-3), loss="categorical_crossentropy", metrics=["accuracy"])
    return model

models = {
    "EffNetB0": build_model(EfficientNetB0(weights="imagenet", include_top=False, pooling="avg", input_shape=(224,224,3))),
    "ResNet50": build_model(ResNet50(weights="imagenet", include_top=False, pooling="avg", input_shape=(224,224,3))),
    "DenseNet121": build_model(DenseNet121(weights="imagenet", include_top=False, pooling="avg", input_shape=(224,224,3)))
}

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

callbacks = [
    EarlyStopping(monitor="val_accuracy", patience=5, restore_best_weights=True),
    ReduceLROnPlateau(monitor="val_accuracy", factor=0.5, patience=3),
]

histories = {}
for name, model in models.items():
    print(f"\nTraining {name}...")
    history = model.fit(
        generator(train_df),
        steps_per_epoch=len(train_df)//BATCH_SIZE,
        validation_data=generator(train_df),
        validation_steps=len(train_df)//BATCH_SIZE,
        epochs=EPOCHS_BASE,
        callbacks=callbacks,
        verbose=1
    )
    histories[name] = history

import os
import numpy as np
import shutil

os.makedirs("/kaggle/working/saved_models", exist_ok=True)

for name, model in models.items():
    model_path = f"/kaggle/working/saved_models/{name}_final.h5"
    hist_path = f"/kaggle/working/saved_models/{name}_history.npy"
    model.save(model_path)
    np.save(hist_path, histories[name].history)
    print(f"Saved {name} -> {model_path}")

print("\nAll models and histories saved to /kaggle/working/saved_models/")

shutil.make_archive("/kaggle/working/mango_models_backup", 'zip', "/kaggle/working/saved_models")
print("Created archive: mango_models_backup.zip")

from tqdm import tqdm

BATCH_SIZE = 32

def preprocess_and_segment(df):
    images = []
    for p in tqdm(df["image_path"], desc="Segmenting images"):
        img = segment_leaf(p)
        images.append(img)
    return np.array(images)

train_imgs = preprocess_and_segment(train_df)
test_imgs = preprocess_and_segment(test_df)

print(train_imgs.shape, test_imgs.shape)

def extract_features_batch(model, img_array):
    feats = model.predict(img_array, batch_size=BATCH_SIZE, verbose=1)
    return feats

print("\nExtracting features...")
train_feats_list = []
test_feats_list = []

for name, m in models.items():
    print(f"\nâ†’ Extracting from {name}")
    train_feats_list.append(extract_features_batch(m, train_imgs))
    test_feats_list.append(extract_features_batch(m, test_imgs))

train_feats = np.hstack(train_feats_list)
test_feats = np.hstack(test_feats_list)

y_train = train_df["label_enc"].values
y_test = test_df["label_enc"].values

scaler = StandardScaler()
train_scaled = scaler.fit_transform(train_feats)
test_scaled = scaler.transform(test_feats)

meta_xgb = xgb.XGBClassifier(n_estimators=800, max_depth=6, learning_rate=0.02, subsample=0.8, colsample_bytree=0.8)
meta_rf = RandomForestClassifier(n_estimators=600, max_features="sqrt")

meta_xgb.fit(train_scaled, y_train)
meta_rf.fit(train_scaled, y_train)

probs = 0.6 * meta_xgb.predict_proba(test_scaled) + 0.4 * meta_rf.predict_proba(test_scaled)
preds = np.argmax(probs, axis=1)

acc = accuracy_score(y_test, preds)
prec = precision_score(y_test, preds, average="macro")
rec = recall_score(y_test, preds, average="macro")
f1 = f1_score(y_test, preds, average="macro")
mcc = matthews_corrcoef(y_test, preds)

print(f"\n Hybrid Accuracy: {acc:.4f}")
print(f"Precision: {prec:.4f}")
print(f"Recall:    {rec:.4f}")
print(f"F1 Score:  {f1:.4f}")
print(f"MCC:       {mcc:.4f}\n")

print(classification_report(y_test, preds, target_names=le.classes_))

cm = confusion_matrix(y_test, preds)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens",
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

specificity = []
sensitivity = []
for i in range(num_classes):
    tn = cm.sum() - (cm[i,:].sum() + cm[:,i].sum() - cm[i,i])
    fp = cm[:,i].sum() - cm[i,i]
    fn = cm[i,:].sum() - cm[i,i]
    tp = cm[i,i]
    specificity.append(tn / (tn + fp + 1e-6))
    sensitivity.append(tp / (tp + fn + 1e-6))

auc_score = roc_auc_score(y_test, probs, multi_class="ovr")

print("\n--- 7 METRICS ---")
print(f"Accuracy:      {acc:.4f}")
print(f"Precision:     {prec:.4f}")
print(f"Recall:        {rec:.4f}")
print(f"F1 Score:      {f1:.4f}")
print(f"Specificity:   {np.mean(specificity):.4f}")
print(f"Sensitivity:   {np.mean(sensitivity):.4f}")
print(f"MCC:           {mcc:.4f}")
print(f"AUC (macro):   {auc_score:.4f}")

per_class_acc = cm.diagonal() / cm.sum(axis=1)
acc_df = pd.DataFrame({
    "Class": le.classes_,
    "Accuracy": per_class_acc
})
print("\n--- Per-Class Accuracy ---")
print(acc_df)

plt.figure(figsize=(8,5))
sns.barplot(x="Class", y="Accuracy", data=acc_df, palette="viridis")
plt.title("Per-Class Accuracy")
plt.xticks(rotation=45)
plt.ylim(0,1)
plt.show()

for name, history in histories.items():
    plt.figure(figsize=(10,4))
    plt.subplot(1,2,1)
    plt.plot(history.history['accuracy'], label='Train Acc')
    plt.plot(history.history['val_accuracy'], label='Val Acc')
    plt.title(f'{name} - Accuracy')
    plt.legend()

    plt.subplot(1,2,2)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title(f'{name} - Loss')
    plt.legend()
    plt.show()

sample_img = test_df.sample(1).iloc[0]
segmented = segment_leaf(sample_img['image_path'])

plt.figure(figsize=(8,4))
plt.subplot(1,2,1)
plt.imshow(cv2.cvtColor(cv2.imread(sample_img['image_path']), cv2.COLOR_BGR2RGB))
plt.title(f"Original: {sample_img['label']}")
plt.axis('off')

plt.subplot(1,2,2)
plt.imshow(segmented)
plt.title("Segmented Leaf")
plt.axis('off')
plt.show()

def grad_cam(model, img_array, layer_name):
    grad_model = tf.keras.models.Model(
        [model.inputs], [model.get_layer(layer_name).output, model.output]
    )
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        class_idx = tf.argmax(predictions[0])
        loss = predictions[:, class_idx]

    grads = tape.gradient(loss, conv_outputs)[0]
    weights = tf.reduce_mean(grads, axis=(0,1,2))
    cam = tf.reduce_sum(tf.multiply(weights, conv_outputs[0]), axis=-1)

    heatmap = np.maximum(cam, 0)
    heatmap /= tf.reduce_max(heatmap)
    heatmap = cv2.resize(heatmap.numpy(), (224, 224))
    return heatmap

img_path = sample_img['image_path']
img = segment_leaf(img_path)[np.newaxis, ...]
heatmap = grad_cam(models["DenseNet121"], img, "conv5_block16_concat")

plt.figure(figsize=(8,4))
plt.subplot(1,2,1)
plt.imshow(segmented)
plt.title("Segmented Leaf")

plt.subplot(1,2,2)
plt.imshow(segmented)
plt.imshow(heatmap, cmap='jet', alpha=0.5)
plt.title("Grad-CAM Heatmap (DenseNet121)")
plt.axis('off')
plt.show()